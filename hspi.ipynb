{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hspi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6b3vtdmtt8eWyaoNfKodZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junsukim-me/tenbagger-community-sentiment-etf/blob/main/hspi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFHvP8UfQwOv"
      },
      "source": [
        "####################################\n",
        "### junsu.kim backtest proj hspi ###\n",
        "####################################\n",
        "### date      : 2021-06-14\n",
        "### last mdfy : 2021-06-22 \n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests, lxml, time, reprlib\n",
        "from datetime import datetime as dt, timedelta\n",
        "\n",
        "import re as regexz\n",
        "import operator\n",
        "\n",
        "import pandas_datareader.data as web\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1vsm5YG22Uy9",
        "outputId": "5d0597ce-469f-4de6-938b-89fa3e9890af"
      },
      "source": [
        "\n",
        "def midReturn(val, s, e):\n",
        "  if s in val:\n",
        "    val = val[val.find(s)+len(s):]\n",
        "    if e in val: val = val[:val.find(e)]\n",
        "  return val\n",
        "\n",
        "def get_num_page_from_date(date_):\n",
        "  # find start page (binany)\n",
        "  pivot_s = 1;\n",
        "  pivot_e = 70000;\n",
        "  pivot_m = (pivot_s+pivot_e) / 2;\n",
        "  target = -1;\n",
        "\n",
        "  while target == -1 :\n",
        "    r = requests.get(link + '&page=' + str(pivot_m), headers = headers).text\n",
        "    bs = BeautifulSoup(r, 'lxml')\n",
        "    posts = bs.find_all('tr', class_='ub-content us-post')\n",
        "    for p in posts:\n",
        "      title = p.find('td', class_='gall_tit ub-word')\n",
        "      if not '<b>' in str(title):\n",
        "        title = p.find('td', class_='gall_tit ub-word')\n",
        "        date = dt.strptime(p.find('td', class_='gall_date').get('title'), \"%Y-%m-%d %H:%M:%S\").replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "        print(date)\n",
        "        if (date > date_) :\n",
        "          pivot_s = pivot_m;\n",
        "          pivot_m = (pivot_s+pivot_e) / 2;\n",
        "          break;\n",
        "    \n",
        "        if (date < date_) :\n",
        "          pivot_e = pivot_m;\n",
        "          pivot_m = (pivot_s+pivot_e) / 2;\n",
        "          break;\n",
        "\n",
        "        if (date == date_) :\n",
        "          target = pivot_m;\n",
        "          break;\n",
        "\n",
        "  while True :\n",
        "    r = requests.get(link + '&page=' + str(target), headers = headers).text\n",
        "    bs = BeautifulSoup(r, 'lxml')\n",
        "    posts = bs.find_all('tr', class_='ub-content us-post')\n",
        "    tmp = target;\n",
        "    for p in posts:\n",
        "      title = p.find('td', class_='gall_tit ub-word')\n",
        "      if not '<b>' in str(title):\n",
        "        title = p.find('td', class_='gall_tit ub-word')\n",
        "        date = dt.strptime(p.find('td', class_='gall_date').get('title'), \"%Y-%m-%d %H:%M:%S\").replace(hour=0, minute=0, second=0, microsecond=0)\n",
        "        print(date)\n",
        "        if (date == date_) :\n",
        "          target += 1 ;\n",
        "          break;\n",
        "        else :\n",
        "          break;\n",
        "      target +=1;\n",
        "    \n",
        "\n",
        "    if tmp == target :\n",
        "      target -= 1;\n",
        "      break;\n",
        "    \n",
        "  return target\n",
        "\n",
        "taskdone = False\n",
        "trial = 0\n",
        "\n",
        "fontpath='font.otf'\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.99 Safari/537.36'\n",
        "}\n",
        "\n",
        "# 해외주식 갤러리 링크\n",
        "link = 'https://gall.dcinside.com/mgallery/board/lists/?id=tenbagger' \n",
        "\n",
        "# 데이터 수집기간 설정\n",
        "str_start = '2021-03-01'\n",
        "str_end = '2021-06-01'\n",
        "str_formatter = \"%Y-%m-%d\"\n",
        "date_start = dt.strptime(str_start,str_formatter);\n",
        "date_end = dt.strptime(str_end,str_formatter);\n",
        "print(str_start + '~' +str_end +'간의 데이터 수집.')\n",
        "\n",
        "# 기간별 검색이 안되기 때문에\n",
        "# 페이지 인덱스하면서 찾음 (바이너리 서치)\n",
        "num_page_start = get_num_page_from_date(date_start);\n",
        "num_page_end = get_num_page_from_date(date_end);\n",
        "\n",
        "# 시작페이지와 끝 페이지 \n",
        "print('stpn='+str(num_page_start));\n",
        "print('edpn='+str(num_page_end));\n",
        "\n",
        "################################################################################################\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-01~2021-06-01간의 데이터 수집.\n",
            "2020-12-02 00:00:00\n",
            "2021-02-10 00:00:00\n",
            "2021-03-12 00:00:00\n",
            "2021-02-23 00:00:00\n",
            "2021-03-04 00:00:00\n",
            "2021-02-26 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-03-01 00:00:00\n",
            "2021-02-28 00:00:00\n",
            "2020-12-02 00:00:00\n",
            "2021-02-10 00:00:00\n",
            "2021-03-12 00:00:00\n",
            "2021-05-01 00:00:00\n",
            "2021-06-03 00:00:00\n",
            "2021-05-19 00:00:00\n",
            "2021-05-28 00:00:00\n",
            "2021-06-02 00:00:00\n",
            "2021-05-31 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-06-01 00:00:00\n",
            "2021-05-31 00:00:00\n",
            "stpn=11571.2109375\n",
            "edpn=2591.2607421875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-78688a30ca3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'===== 페이지 읽는 중... [{}번째...] ====='\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, end='\\r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mtitleok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2yCOovHn_Fd"
      },
      "source": [
        "### 공사중\n",
        "print('stpn='+str(num_page_start));\n",
        "print('edpn='+str(num_page_end));\n",
        "\n",
        "\n",
        "taskdone = False\n",
        "trial = 0\n",
        "\n",
        "prev_num = 0\n",
        "\n",
        "while not taskdone and trial < 10:\n",
        "    data = 'Post ID\\tTitle\\tNickname(IP)\\tDate\\tViewcount\\tUpvoteCount\\n'\n",
        "\n",
        "    pidlst = []\n",
        "    titlelst = []\n",
        "\n",
        "    fin = False\n",
        "    r = None\n",
        "\n",
        "    while not fin:\n",
        "        time.sleep(0.5)\n",
        "        \n",
        "        i += 1\n",
        "        print('===== 페이지 읽는 중... [{}번째...] ====='.format(i))#, end='\\r')\n",
        "        titleok = False\n",
        "\n",
        "        while not titleok:\n",
        "            r = requests.get(link + '&page=' + str(i), headers = headers).text\n",
        "            bs = BeautifulSoup(r, 'lxml')\n",
        "\n",
        "            posts = bs.find_all('tr', class_='ub-content us-post')\n",
        "\n",
        "            for p in posts:\n",
        "                title = p.find('td', class_='gall_tit ub-word')\n",
        "\n",
        "                # 공지 제외 (볼드태그 찾을때 str 처리 해줘야 찾기가능)\n",
        "                if not '<b>' in str(title):\n",
        "                    titleok = True\n",
        "                    pid = p.find(\"td\", {\"class\", \"gall_num\"}).text.strip()\n",
        "                    title = midReturn(str(title), '</em>', '</a>')\n",
        "                    nick = p.find(\"td\", {\"class\", \"gall_writer ub-writer\"}).text.strip()\n",
        "                    date = datetime.strptime(p.find('td', class_='gall_date').get('title'), \"%Y-%m-%d %H:%M:%S\")\n",
        "                    view = p.find(\"td\", {\"class\", \"gall_count\"}).text.strip()\n",
        "                    recom = p.find(\"td\", {\"class\", \"gall_recommend\"}).text.strip()\n",
        "                    #print(pid + \"\\t\" + str(date) + \"\\t\" + re.repr(nick) + \"\\t\\t\" + re.repr(title))\n",
        "\n",
        "                    # 이전 넘버링보다 현재 넘버링이 적을 경우에만 읽기\n",
        "                    if prev_num > int(pid) or prev_num == 0:\n",
        "                        \n",
        "                        #초 단위까지는 안 가도록 함\n",
        "                        if date >= ystday:\n",
        "                            data += pid + \"\\t\" + title + \"\\t\" + nick + \"\\t\" + str(date) + \"\\t\" + view + \"\\t\" + recom + \"\\n\"\n",
        "                            pidlst.append(pid)\n",
        "                            titlelst.append(title)\n",
        "                            \n",
        "\n",
        "                        else:\n",
        "                            fin = True\n",
        "                            date = ystday\n",
        "                            break\n",
        "                            '''\n",
        "                            ask = input('중지하시겠습니까? [Y/n]: ')\n",
        "                            if ask == 'y' or ask == 'Y':\n",
        "                                print('[NO]' + title)\n",
        "                                print('기간 초과:', date)\n",
        "                                fin = True\n",
        "                                date = ystday\n",
        "                                break\n",
        "                            else:\n",
        "                                data += pid + \"\\t\" + title + \"\\t\" + nick + \"\\t\" + str(date) + \"\\t\" + view + \"\\t\" + recom + \"\\n\"\n",
        "                            '''\n",
        "\n",
        "                        prev_num = int(pid)\n",
        "                        \n",
        "                    else:\n",
        "                        print(pid + '\\t올바르지 않은 글 넘버 - 무시하고 계속 읽습니다.')\n",
        "                    \n",
        "            if not titleok:\n",
        "                print('게시글 크롤링 실패. 5초 후 다시 시도해 봅니다.')\n",
        "                #i -= 1\n",
        "                time.sleep(5)\n",
        "    print('저장 완료')\n",
        "    taskdone = True\n",
        "\n",
        "\n",
        "print(\"파일 쓰는 중...\")\n",
        "open(filename + '.tsv', 'w', encoding='utf-8-sig').write(data)\n",
        "print(\"쓰기 완료.\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download(filename + '.tsv') \n",
        "\n",
        "#print(len(pidlst))\n",
        "#print(len(titlelst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGFH6HeDJ7DH"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(filename + '.tsv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c2XWCca8A6e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kNPY_OPDjkz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE4Ekfnw1Ur3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xvy9-ZhudOr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVoHuBGkp9Xl"
      },
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.download('1.tsv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCMfY9kg9HSl"
      },
      "source": [
        "#from google.colab import files\n",
        "#files.download(filename + '.tsv') \n",
        "\n",
        "from google.colab import files\n",
        "files.download(filename + '.tsv') \n",
        "\n",
        "fulltitle ='';\n",
        "for i in titlelst :\n",
        "  fulltitle += (' ' + i)\n",
        "\n",
        "p =regexz.findall('[a-zA-Z]+',fulltitle)\n",
        "\n",
        "count={}\n",
        "for i in p:\n",
        "    try: count[i.upper()] += 1\n",
        "    except: count[i.upper()]=1\n",
        "#print(count)\n",
        "\n",
        "sdict= sorted(count.items(), key=operator.itemgetter(1))\n",
        "\n",
        "sdict.reverse()\n",
        "\n",
        "##티커가 아닌것들으 제거 해야됨.\n",
        "##\n",
        "\n",
        "#print(type(sdict))\n",
        "\n",
        "dellst = ['ETF','LT','GT','CEO','IPO','G','K','TXT','GIF','JPG','FDA','VS','MACD','RSI']\n",
        "i=0\n",
        "while i < len(sdict):\n",
        "  if (sdict[i][0] in dellst ) :\n",
        "     del sdict[i]\n",
        "     i -=1\n",
        "  i += 1\n",
        "\n",
        "sdict30 = dict(sdict[0:10]) #해스피30\n",
        "sdict30\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHACFOGELxMN"
      },
      "source": [
        "hspiTicker = list(sdict30.keys())\n",
        "#print(hspiTicker)\n",
        "hspiRatio = []\n",
        "sum=0\n",
        "for i in hspiTicker :\n",
        "  sum += sdict30[i]\n",
        "\n",
        "for i in hspiTicker :\n",
        "  sdict30[i] = sdict30[i] / sum\n",
        "\n",
        "assets = web.get_data_yahoo(hspiTicker, start='1989-12-01', end='2021-06-02',interval='m')['Adj Close'].pct_change()\n",
        "\n",
        "assets.index = assets.index.strftime(\"%Y-%m\") \n",
        "assets.index = pd.to_datetime(assets.index).to_period(\"M\")\n",
        "\n",
        "\n",
        "#assets=ind10_ret.join(assets,how='left', lsuffix='', rsuffix='')\n",
        "#assets.dropna(inplace=True)\n",
        "assets = assets.fillna(0)\n",
        "\n",
        "assets_mean = assets.mean()\n",
        "assets_var = assets.var()\n",
        "assets_cov = assets.cov() #assets_var\n",
        "\n",
        "assets\n",
        "sdict30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVYiuNjNc1oR"
      },
      "source": [
        "### asset allocation weights\n",
        "\n",
        "### 1.hspiRatio\n",
        "hspiRatio\n",
        "\n",
        "\n",
        "### 2.equal weight (EWI)\n",
        "EWI = [1/30]*30\n",
        "\n",
        "weight_df = pd.DataFrame([],columns = assets.columns)\n",
        "weight_df.index.name = \"Date\"\n",
        "\n",
        "\n",
        "### 백테스트\n",
        "def _date_str_to_int(date):\n",
        "    y, m = date.split('-')\n",
        "    y, m = int(y), int(m)\n",
        "    return y,m\n",
        "\n",
        "def _cal_date_with_month(date, mon, oper='-'):\n",
        "    y, m = _date_str_to_int(date)\n",
        "    if oper == '-':\n",
        "        if m-mon < 1:\n",
        "            m= m-mon\n",
        "            while m < 1:\n",
        "              y -= 1\n",
        "              m = m + 12\n",
        "        else:\n",
        "            m -= mon\n",
        "\n",
        "    elif oper == '+':\n",
        "        if m+mon > 12:\n",
        "            m=m+mon\n",
        "            while m > 12:\n",
        "              y += 1\n",
        "              m = m - 12\n",
        "        else:\n",
        "            m += mon\n",
        "\n",
        "    return '{0:04d}-{1:02d}'.format(y,m)\n",
        "\n",
        "def _df_to_estimate(self, df):\n",
        "    \"\"\"\n",
        "        === Description ===\n",
        "\n",
        "    함수 설명: 최적화 문제를 풀기 위해 필요한 estimate를 계산\n",
        "\n",
        "    * df: estimate 계산에 이용\n",
        "\n",
        "    output: estimate list \n",
        "            ex) return, variance, covariance matrix (추후에 list에 다 넣기에는 형식이 애매하면 dictionary를 이용하거나,\n",
        "                                                    새로 class 작성해서 넘겨주는 방식도 고려해볼 수 있을수도)\n",
        "\n",
        "    # 현재(11/19) backtest에서는 아래 형식으로 구성되었다고 가정하였습니다.\n",
        "      est_lst[0]: mean lst ex) [0.5,0.3, ..., 0.7] \n",
        "      est_lst[1]: var lst ex) [...]\n",
        "      est_lst[2]: cov matrix ex) [[...],[...],...]\n",
        "      est_lst[3]: holding-period return \n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    n=4\n",
        "    est_lst = [0 for i in range(n)]\n",
        "\n",
        "    est_lst[0] = df.mean()\n",
        "    est_lst[1] = df.var()\n",
        "    est_lst[2] = df.cov()\n",
        "    #lookback 기간동안 발생한 holding-period return\n",
        "    s = {}\n",
        "    for i in df.columns:\n",
        "        val = df.get(i)\n",
        "        hldprd_ret = 1.0\n",
        "        for j in val : \n",
        "            j += 1   #ror -> total return 곱연산으로 기간의 수익을 가져오기 위함.\n",
        "            hldprd_ret*=j\n",
        "            s.update({i:hldprd_ret})\n",
        "\n",
        "    est_lst[3] = pd.Series(s)\n",
        "    est_lst[3] = est_lst[3] - 1 #total return -> ror\n",
        "    \n",
        "    return est_lst\n",
        "\n",
        "def _pfo_return(mean, weight_lst):\n",
        "    \"\"\"\n",
        "    === Description ===\n",
        "    포트폴리오 return 계산\n",
        "\n",
        "    * parameter *\n",
        "    #est_mean: 특정 기간동안 estimate한 자산들의 평균 수익률 /type:Series\n",
        "    mean: 수익률 /type:Series\n",
        "    weight_lst: (가정)최적화를 통해 구한 weight / type:Series\n",
        "\n",
        "    output: pfo return / type: float\n",
        "\n",
        "    \"\"\"\n",
        "    ptf_ret = mean @ weight_lst\n",
        "\n",
        "    return ptf_ret\n",
        "\n",
        "\n",
        "inv_start = '2021-02'\n",
        "inv_end = '2021-06'\n",
        "amount = 1000\n",
        "method = 'mention-weight'\n",
        "lookback_period = 3\n",
        "\n",
        "tmp_res = pd.DataFrame([], columns = [\"{}_{}_return\".format(hspiTicker, method),\"{}_{}_balance\".format(hspiTicker, method)])\n",
        "\n",
        "size = len(assets.columns)\n",
        "pfo_amount = np.array([1.0/size]*size)*amount\n",
        "\n",
        "tmp_res.loc[\"Initial\"] = [0, amount] #res_df 초기값\n",
        "\n",
        "tmp_date = inv_start\n",
        "tmp_end = _cal_date_with_month(inv_end, 1,'+')\n",
        "\n",
        "while tmp_date != tmp_end:\n",
        "  #look_start = _cal_date_with_month(tmp_date, lookback_period,'-')\n",
        "  #lookback_df = assets.loc[look_start:tmp_date][:-1]\n",
        "  #est_lst = self._df_to_estimate(lookback_df)\n",
        "\n",
        "  j=0\n",
        "  weight_dict = sdict30\n",
        "  weight_lst = pd.Series(weight_dict)\n",
        "\n",
        "  \n",
        "  pfo_amount *= (assets.loc[tmp_date] + 1) #각 산업군 (amount * (1+수익률))\n",
        "  print(tmp_date)\n",
        "  print(weight_lst)\n",
        "  print(assets.loc[tmp_date])\n",
        "  s = _pfo_return(assets.loc[tmp_date], weight_lst)\n",
        "  print(s)\n",
        "  amount *= (s+1)\n",
        "  print(amount)\n",
        "\n",
        "  \n",
        "  #print([_pfo_return(assets.loc[tmp_date], weight_lst), sum(pfo_amount)])\n",
        "  #tmp_res.loc[tmp_date] = [_pfo_return(assets.loc[tmp_date], weight_lst), sum(pfo_amount)]   \n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  tmp_date = _cal_date_with_month(tmp_date, 1, '+')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 퍼포먼스 이벨류에이션\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}